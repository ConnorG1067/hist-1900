Source: [[@southwellMisinformationMisunderstoodChallenge2019]]

> [!quote|#5fb236] Highlight
> For an algorithm to identify, flag, and correct a piece of misinformation still requires a series of human-initiated tasks. Who can best identify and choose the types of misinformation to be corrected and the appropriate response?
>
>> Excellent point. Someone has to identify misinformation which is rooted in their own biases. An algorithm which detects misinformation is useful but not perfect. This algorithm obtains the biases of its creator, the human.
>
> [Page 3](zotero://open-pdf/library/items/MIST2VSE?page=3) [[2023-02-09#7:26 pm]]

Nowadays we have shopisticated algoritms designed to detect hate, misinformation, disinformation, etc. However these algorithms must be inheritly bias. A human with their own biases created said program and thus the algorithm has an underlying bias. Misinformation is based on the persecption of the individuals beliefs. So when we claim something is misinformation there is a bit of gray area. The individual could think they're right when in reality they're not, they've been decieved.  On an individual level this is essentially harmless, however, online, especially on #social-media the person who creates the algorithm controls the flows of information, that is the #Mediums-and-messages.

### Key Take Aways:
Detecting misinformation online is difficult, simply because certain things flagged as misinformation could be true. It's also problematic because algorithms have biases and thus these algorithms which exist today censor people who deserve the freedom to express themselves. There are exceptions and these algorithms typically preforms relatively well.